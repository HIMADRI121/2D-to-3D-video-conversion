{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Tuple, Optional\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VideoTo3DConverter:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the 2D to 3D converter with default parameters\"\"\"\n",
    "        self.depth_estimation_model = None  # Placeholder for a depth estimation model\n",
    "        \n",
    "    def generate_depth_map(self, frame: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate a depth map from a single frame.\n",
    "        This is a simplified version - in practice, you'd want to use\n",
    "        a pre-trained deep learning model for better results.\n",
    "        \n",
    "        Args:\n",
    "            frame: Input frame in BGR format\n",
    "            \n",
    "        Returns:\n",
    "            Depth map as grayscale image\n",
    "        \"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(gray, (15, 15), 0)\n",
    "        \n",
    "        # Use Sobel operators to detect edges\n",
    "        sobel_x = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobel_y = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        \n",
    "        # Compute gradient magnitude\n",
    "        gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "        \n",
    "        # Normalize to 0-255 range\n",
    "        depth_map = cv2.normalize(gradient_magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        \n",
    "        return depth_map.astype(np.uint8)\n",
    "    \n",
    "    def create_stereo_pair(self, \n",
    "                          frame: np.ndarray, \n",
    "                          depth_map: np.ndarray,\n",
    "                          shift_scale: float = 0.05) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Create left and right views based on the depth map.\n",
    "        \n",
    "        Args:\n",
    "            frame: Input frame\n",
    "            depth_map: Corresponding depth map\n",
    "            shift_scale: Scale factor for pixel shifting\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of left and right view images\n",
    "        \"\"\"\n",
    "        height, width = frame.shape[:2]\n",
    "        \n",
    "        # Create displacement maps for left and right views\n",
    "        displacement = (depth_map.astype(float) * shift_scale).astype(np.float32)\n",
    "        \n",
    "        # Create matrices for remapping\n",
    "        x_map = np.tile(np.arange(width), (height, 1)).astype(np.float32)\n",
    "        y_map = np.tile(np.arange(height), (width, 1)).T.astype(np.float32)\n",
    "        \n",
    "        # Create left view (shift right)\n",
    "        left_x_map = x_map + displacement\n",
    "        left_view = cv2.remap(frame, left_x_map, y_map, cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Create right view (shift left)\n",
    "        right_x_map = x_map - displacement\n",
    "        right_view = cv2.remap(frame, right_x_map, y_map, cv2.INTER_LINEAR)\n",
    "        \n",
    "        return left_view, right_view\n",
    "    \n",
    "    def create_anaglyph(self, left_view: np.ndarray, right_view: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Create a red-cyan anaglyph from stereo pair.\n",
    "        \n",
    "        Args:\n",
    "            left_view: Left eye view\n",
    "            right_view: Right eye view\n",
    "            \n",
    "        Returns:\n",
    "            Anaglyph image\n",
    "        \"\"\"\n",
    "        # Split the views into color channels\n",
    "        left_b, left_g, left_r = cv2.split(left_view)\n",
    "        right_b, right_g, right_r = cv2.split(right_view)\n",
    "        \n",
    "        # Create anaglyph (red channel from left, blue/green from right)\n",
    "        anaglyph = cv2.merge([right_b, right_g, left_r])\n",
    "        \n",
    "        return anaglyph\n",
    "    \n",
    "    def convert_video(self, \n",
    "                     input_path: str, \n",
    "                     output_path: str,\n",
    "                     shift_scale: float = 0.05) -> None:\n",
    "        \"\"\"\n",
    "        Convert an entire video from 2D to 3D.\n",
    "        \n",
    "        Args:\n",
    "            input_path: Path to input video file\n",
    "            output_path: Path to save output video\n",
    "            shift_scale: Scale factor for stereo separation\n",
    "        \"\"\"\n",
    "        # Open input video\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(\"Could not open input video\")\n",
    "            \n",
    "        # Get video properties\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        \n",
    "        # Create video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Generate depth map\n",
    "            depth_map = self.generate_depth_map(frame)\n",
    "            \n",
    "            # Create stereo pair\n",
    "            left_view, right_view = self.create_stereo_pair(frame, depth_map, shift_scale)\n",
    "            \n",
    "            # Create anaglyph\n",
    "            anaglyph = self.create_anaglyph(left_view, right_view)\n",
    "            \n",
    "            # Write frame\n",
    "            out.write(anaglyph)\n",
    "            \n",
    "        # Release resources\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    converter = VideoTo3DConverter()\n",
    "    \n",
    "    try:\n",
    "        converter.convert_video(\n",
    "            input_path='Hostel_2_video.mp4',\n",
    "            output_path='Output_hostel_2_3d_video.mp4',\n",
    "            shift_scale=0.05\n",
    "        )\n",
    "        print(\"Conversion completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during conversion: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
